from airflow import DAG

from airflow.operators.python_operator import PythonOperator

from datetime import datetime, timedelta

import pymonetdb

import subprocess

import logging

import time

def read_industry_names(filename):

    with open(filename, 'r') as file:

        return [line.strip() for line in file]

def read_industries(filename):

    with open(filename, 'r') as file:

        return [line.strip() for line in file]

def read_monetdb_credentials(filename):

    credentials = {}

    with open(filename, 'r') as file:

        for line in file:

            key, value = line.strip().split('=')

            credentials[key] = value

    return credentials

# File paths

industry_names_file = '/path/to/industry_names.txt'

industries_file = '/path/to/industries.txt'

monetdb_credentials_file = '/path/to/monetdb_credentials.txt'

# Read industry names and industries from files

industry_names = read_industry_names(industry_names_file)

industries = read_industries(industries_file)

# Read MonetDB connection credentials from file

monetdb_credentials = read_monetdb_credentials(monetdb_credentials_file)

def execute_monet_query(industry_name, industry, monetdb_credentials):

    conn = pymonetdb.connect(username=monetdb_credentials['username'], password=monetdb_credentials['password'], hostname=monetdb_credentials['hostname'], port=int(monetdb_credentials['port']), database=monetdb_credentials['database'])

    cursor = conn.cursor()

    

    

    with open('/path/to/execution_log_query.sql', 'r') as query_file:

        query_var=query_file.read()

        print(query_var)

        query_assign=query_var

        print(industry_name)

        query_assign = query_file.read().replace('{industry_name}', industry_name)

        print(query_assign)

    #query = f'''select count(*) from "execution_log" where operation_type='ab' and job_status='SUCCESS' and sys.str_to_date("execution_end_time",'%y-%m-%d')=current_date AND industry_name='{industry_name}' and flag='0' '''

    cursor.execute(query_assign)

    print(query)

    logging.info("executed above execution log table query")

    results = cursor.fetchone()[0]

    results = int(results)

    print(results)

    #query_two = f'''select offline_mart from "LATES_REFRESH_DETAILS" WHERE industry='{industry}' '''

    with open('/path/to/latest_refresh_query.sql', 'r') as query_file_two:

        query_var_two=query_file.read()

        print(query_var_two)

        query_assign_two=query_var_two

        print(industry_name)

        query_assign_two = query_file_two.read().replace('{industry}', industry)

        print(query_assign_two)

    cursor.execute(query_assign_two)

    result_two = cursor.fetchone()[0]

    print(result_two)

    if results > 0:

        if result_two == 'B':

            industry_name=industry_name.upper()

            dag_id = f'US_{industry_name}_B'

            logging.info("B side dag was triggerd")

            subprocess.run(['airflow', 'dags','trigger' dag_id])

            industry_name=industry_name.lower()

            time.sleep(30)

            #update_query = f'''UPDATE "execution_log" SET dag_flag=1 WHERE  operation_type='ab' and job_status='SUCCESS' and sys.str_to_date("execution_end_time",'%y-%m-%d')=current_date AND industry_name='{industry_name}' AND dag_flag=0 '''

            with open('/path/to/update_query_latest_refresh_one.sql', 'r') as query_file_three:

                query_var_three=query_file_three.read()

                print(query_var_three)

                query_assign_three=query_var_three

                print(industry)

                query_assign_three = query_var_three.read().replace('{industry}', industry)

                print(query_assign_three)

            cursor.execute(query_assign_three)

            time.sleep(10)

            print(query_assign_three)

            conn.commit()

            

            

            with open('/path/to/update_query_execution_log_one.sql', 'r') as query_file_four:

                query_var_four=query_file_four.read()

                print(query_var_four)

                query_assign_four=query_var_four

                print(industry_name)

                query_assign_four = query_file_four.read().replace('{industry_name}', industry_name)

                print(query_file_four)

            cursor.execute(query_file_four)

            time.sleep(10)

            print(query_file_four)

            conn.commit()

        

            #update_query_two = f'''UPDATE "LATES_REFRESH_DETAILS" SET offline_mart='A', online_mart='B' where industry='{industry}' '''

            #cursor.execute(update_query_two)

            #conn.commit()

        else:

            industry_name=industry_name.upper()

            dag_id = f'US_{industry_name}_A'

            logging.info("A side dag was triggerd")

            subprocess.run(['airflow', 'dags','trigger', dag_id])

            industry_name=industry_name.lower()

            print(industry)

            #update_query_two = f'''UPDATE "LATES_REFRESH_DETAILS" SET offline_mart='B', online_mart='A' where industry='{industry}' '''

            with open('/path/to/update_query_latest_refresh_two.sql', 'r') as query_file_five:

                query_var_five=query_file_five.read()

                print(query_var_five)

                query_assign_five=query_var_five

                print(industry)

                query_assign_five = query_file_five.read().replace('{industry}', industry)

                print(query_assign_five)

            cursor.execute(query_assign_five)

            time.sleep(10)

            print(query_assign_five)

            conn.commit()

            #cursor.execute(update_query_two)

            

            with open('/path/to/update_query_execution_log_two.sql', 'r') as query_file_six:

                query_var_six=query_file_six.read()

                print(query_var_six)

                query_assign_six=query_var_six

                print(industry)

                query_assign_six = query_file_six.read().replace('{industry}', industry)

                print(query_assign_six)

            cursor.execute(query_assign_six)

            time.sleep(10)

            print(query_assign_six)

            conn.commit()

            #cursor.execute(update_query_two)

    else:

        print("No data loaded from the source side")

    cursor.close()

    conn.close()

default_args = {

    'max_active_runs': 1

}

dag = DAG(

    "Monet_testing",

    default_args=default_args,

    schedule_interval='*/5 * * * *',

    start_date=datetime(2023, 5, 14),

    catchup=False,

)

# Create tasks dynamically

for industry_name, industry in zip(industry_names, industries):

    execute_query_task=PythonOperator(

        task_id=f'execute_monet_query_{industry_name}',

        python_callable=execute_monet_query,

        op_kwargs={'industry_name':industry_name, 'industry': industry, 'monetdb_credentials':monetdb_credentials},

        dag=dag,

        )
