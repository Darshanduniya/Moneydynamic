
from airflow import DAG
from airflow.operators.python_operator import PythonOperator
from datetime import datetime, timedelta
import pymonetdb
import subprocess
import logging

def read_industry_names(filename):
    with open(filename, 'r') as file:
        return [line.strip() for line in file]

def read_industries(filename):
    with open(filename, 'r') as file:
        return [line.strip() for line in file]

def read_monetdb_credentials(filename):
    credentials = {}
    with open(filename, 'r') as file:
        for line in file:
            key, value = line.strip().split('=')
            credentials[key] = value
    return credentials

# File paths
industry_names_file = '/path/to/industry_names.txt'
industries_file = '/path/to/industries.txt'
monetdb_credentials_file = '/path/to/monetdb_credentials.txt'

# Read industry names and industries from files
industry_names = read_industry_names(industry_names_file)
industries = read_industries(industries_file)

# Read MonetDB connection credentials from file
monetdb_credentials = read_monetdb_credentials(monetdb_credentials_file)

def execute_monet_query(industry_name, industry, credentials):
    conn = pymonetdb.connect(username=credentials['username'], password=credentials['password'], hostname=credentials['hostname'], port=int(credentials['port']), database=credentials['database'])
    cursor = conn.cursor()

    query = f'''select count(*) from "execution_log" where operation_type='ab' and job_status='SUCCESS' and sys.str_to_date("execution_end_time",'%y-%m-%d')=current_date AND industry_name='{industry_name}' and flag='0' '''
    cursor.execute(query)

    results = cursor.fetchone()[0]
    results = int(results)

    query_two = f'''select offline_mart from "LATES_REFRESH_DETAILS" WHERE industry='{industry}' '''
    cursor.execute(query_two)

    result_two = cursor.fetchone()[0]
    print(result_two)

    if results > 0:
        if result_two == 'B':
            dag_id = f'{industry_name}_B'
            subprocess.run(['airflow', 'dags', dag_id])

            update_query = f'''UPDATE "execution_log" SET dag_flag=1 WHERE  operation_type='ab' and job_status='SUCCESS' and sys.str_to_date("execution_end_time",'%y-%m-%d')=current_date AND industry_name='{industry_name}' AND dag_flag=0 '''
            cursor.execute(update_query)

            update_query_two = f'''UPDATE "LATES_REFRESH_DETAILS" SET offline_mart='A', online_mart='B' where industry='{industry}' '''
            cursor.execute(update_query_two)
            conn.commit()
        else:
            dag_id = f'{industry_name}_A'
            subprocess.run(['airflow', 'dags', dag_id])

            update_query_two = f'''UPDATE "LATES_REFRESH_DETAILS" SET offline_mart='B', online_mart='A' where industry='{industry}' '''
            cursor.execute(update_query_two)
    else:
        print("validation issue")

    cursor.close()
    conn.close()

default_args = {
    'max_active_runs': 1
}

dag = DAG(
    "Monet_testing",
    default_args=default_args,
    schedule_interval='*/5 * * * *',
    start_date=datetime(2023, 5, 14),
    catchup=False,
)

# Create tasks dynamically
for industry_name, industry in zip(industry_names, industries
